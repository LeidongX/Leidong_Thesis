\cleardoublepage

\chapter{Introduction}
\label{chapter:intro}
Nuclear power was initially studied in the 1940s and has become an important source in the power industry.
The nuclear reactor core containing the fuel is where the chain reactions take place and the heat is generated from, which is the foremost component of the nulcear power plant. 
Without estimating the desired state of neutron population, it is impossible to control the neutronic systems and generate essential design. 
In nuclear physics, computational simulations are critical for optimizing nuclear reactor designs and helping to understand extremely complicated neutron dynamic behaviors.
However, modeling a full core is still too computationally expensive even with the most advanced, large-scale, super computers. 
Therefore, having an accurate and efficient approach to determine the criticality and the neutron distribution is a pivotal topic in this field.

\section{Operator Notation}
The generalized eigenvalue form of the neutron transport equation is a fundamental problem in computational reactor physics.
The dominant eigenvector and corresponding eigenvalue of this equation can represent if a system is in steady-state conditions.
Though criticality calculations arose from the analysis of time-dependent processes, it is sufficient to reduce the transport equation to steady-state in many cases. 
The steady-state transport equation can be written in operator notation as
\begin{equation}
 \mathbf{(I - DL^{-1}MS)} \mathbf{\phi} = \frac{1}{k} \mathbf{DL^{-1}MF} \mathbf{\phi}  \, ,
 \label{eq:keig}
\end{equation}
where $\mathbf{\phi} $ describes the scalar flux, $\mathbf{L}$ represents loss operator,  $\mathbf{F}$ represents fission operator, $\mathbf{S}$ represents the scattering operator, $\mathbf{M}$ and $\mathbf{D}$ represent moment-to-discrete and discrete-to-moment operators respectively, and the eigenvalue $k$ represents the ratio of gains to losses.
A reactor is ``critical,'' i.e., the neutron population is steady, when $k = 1$; or ``subcritical,'' i.e., the neutron density is decreasing as time passes when $k < 1$; or ``supercritical,'' i.e., the neutron density is increasing with time when $k>1$.
The eigenvector corresponding to the largest eigenvalue $k$, which is usually known as fundamental (or dominant) eigenmode, indicates the scalar flux distribution when the system reaches steady state.
A more generalized multigroup neutron transport equation will be presented in Chapter 2.

\section{Motivation and Objective}
The discrete ordinates method is a practical, deterministic approach that is used to solve \EQ{eq:keig}.
This approach is often smoothed by other iterative methods such as the power method, Richard iteration method, or GMRES, which each apply the loss operator $L$ every iteration.
Numerically, it is inefficient to solve for the operator inverse; instead, a series of sweeps over each energy group and space location can be performed until the system converges.  
However, the expense of this approach is now proportional to the number of iterations.
Many breakthrough, such as the generalized Davidson(GD) method\cite{larsen1984diffusion} and Diffusion Synthetic Acceleration(DSA)\cite{hamilton2011numerical}, came to accelerate the aforementioned iteration methods.

Within the development of computational science，some theory of data science has been employed to analyze engineering problems.
Dynamic mode decomposition(DMD) is one of the most well-known supervised learning approaches that has achieved great success in computational fluid dynamics.
This data-driven technology can produce reduced-dimensional surrogate models by gathering modes from given states of time dependent data and reconstructing the output parameters.
The primary focus of this thesis is to estimate accurate fundamental eigenmodes by DMD to accelerate the Power Method and other, related methods.

To achieve these goals, a review of DMD will be described in the remainder of this chapter.
\CHAPTER{chapter:multigroup} will introduce the multigroup neutron transport and diffusion equations, and \CHAPTER{chapter:PM} discusses the mathematical background of the power and flatten power methods.
Following that, a scheme using DMD to accelerate the power method is presented in \CHAPTER{chapter:DMD-PM}, while the DMD-FPM(n) scheme is presented in \CHAPTER{chapter:DMD-FPM(n)}.
Then, the results using either of acceleration schemes on compute analyzing a 1-D boiling water reactor(BWR) model and the famous 2-D C5G7 test problem, are discussed in \CHAPTER{chapter:results}.
\CHAPTER{chapter:conclusion} will include conclusions and future work including the possibility of combining this theory with other methods. 


\section{Summary of previous work}
Before continuing, it would be useful to briefly introduce some great achievements that demonstrated the success of dynamic mode decomposition.
DMD was initially proposed by \citet{schmid_dynamic_2010}\cite{schmid_applications_2011} to extract dynamics information from time-series data of fluids observations in 2010.
He applied this frame on both numerical Navier-Stokes code results and experimental measures and illustrated the significant essential on quantifying fluid-dynamical problems.
As opposed to proper orthogonal decomposition(POD), DMD is a pure data-based procedure and does not decompose on an orthogonal space. 
This method is based on Koopman analysis of nonlinear dynamical systems and can extracte dynamic modes to describe the global behavior captured by projecting large-scale problems onto a reduced order dynamical system.
In his work, the time-dependent dynamic systems are described in the form of a snapshots sequence,
\begin{equation}
 \mathbf{X}^{N}_1 = \{\mathbf{x}_0, \mathbf{x}_1, \ldots, \mathbf{x}_{N} \} \, ,
 \label{eq:snap_matrix}
\end{equation}
where $\mathbf{x}_i$ stands for the {\it i}th state.
We assume that there exist a linear mapping operator $\mathbf{A}$, which can be applied on on the initial data snapshot $\mathbf{x}_0$ repeatedly and formulate snapshots sequence \EQ{eq:snap_matrix} as a Krylov sequence by
\begin{equation}
 \mathbf{X}^{N}_1 = \{\mathbf{x}_1,A\mathbf{x}_1,A^2\mathbf{x}_1,…,A^{N-1}\mathbf{x}_1 \} \, .
 \label{eq:Krylov_seq}
\end{equation}
Some famous older attempts, like Arnoldi method, uses QR-decomposition $\mathbf{QR} = \mathbf{X}^{N-1}_1$ to reconstruct the mapping operator, which is not applicable while the matrix $A$ has to be available explicitly for the projections.\cite{Greenbaum_1997}  \cite{trefethen1997numerical}
Instead of employing the QR-decomposition, Schmid took advantage of the SVD decomposition and obtained a robust approximation by 
\begin{equation}
\mathbf{\tilde{A}} = \mathbf{U^H X_1^{N-1}V\Sigma^{-1}} \, ,
 \label{eq:stanard_DMD}
\end{equation}
where $\mathbf{X}_1^{N-1} = \mathbf{U}\Sigma \mathbf{V}^H$. 
The eigenvector $x_i$ of $\mathbf{\tilde{A}}$ and left eigenvector matrix $\mathbf{U}$ are used to calculate the DMD modes $\mathbf{\Phi}_i$ by 
\begin{equation}
\mathbf{\Phi}_i = \mathbf{U} \mathbf{x}_i \, ,
 \label{eq:dyanmic_modes}
\end{equation}
and, therefore, recover the a reduced order dynamic system.
This scheme is often known as the standard DMD approach, and a more detailed discussion of the standard DMD scheme is presented in \CHAPTER{chapter:DMD-PM}.   

Many practical theory were developed based on the this successfully attempt, and past and future snapshot matrix is defined as $\mathbf{X}_0 \triangleq \{\mathbf{x}_0, \mathbf{x}_1, \ldots, \mathbf{x}_{N-1} \}$ and $\mathbf{X}_1 \triangleq \{\mathbf{x}_1, \mathbf{x}_1, \ldots, \mathbf{x}_{N} \} $. 
\citet{tu_dynamic_2014} posted a delicate mathematical analysis of the DMD algorithm and develop a theoretical extension of DMD(extract DMD) using a new definition of operater $\mathbf{A}$ by    
\begin{equation}
 \mathbf{A}\triangleq \mathbf{X}_1  \mathbf{X}_0^{\dagger}\, ,
 \label{eq:exact_dmd}
\end{equation}
where $\mathbf{X}_0^{\dagger}$ is the pseudoinverse of $\mathbf{X}_0$. And the DMD modes and
eigenvalues are the eigenvectors and eigenvalues of $\mathbf{A}$, which can be computed by eigendecomposition. However, in practice, it may be expensive to compute the eigendecomposition of $\mathbf{A}$. With very minimum changes, exact DMD can also compute the modes and eigenvalue without manipulate explicit $\mathbf{A}$. In the case of directly-manipulation-free extract DMD, all other processes keep consistent with standard DMD, but the DMD modes are computed by 
\begin{equation}
 \mathbf{\Phi}_i = \frac{1}{\lambda} \mathbf{X}_1 \mathbf{V} \mathbf{\Sigma}^{-1} \omega \, .
 \label{eq:exact_dmd_free}
\end{equation}

\citet{kutz_dynamic_2016} summarized many other fashion variety DMD algorithms and discussed the applicability fitting with different complex systems in a recent monograph.
Fundamental theoretical foundations of DMD and the Koopman operator was also developed in this book.

\subsection{DMD in Nuclear Engineering}
Soon after, this technology then was applied in nuclear reactor simulation. 
Abdo and others used DMD as a direct, explicit-in-time surrogate for such black-box models, e.g., to model the evolution of nuclear reactor isotopics over long time periods; and the nonlinear response of reactor power during short transients.\cite{abdo_data-driven_2018}\cite{abdo_modeling_2019}\cite{elzohery2018comparison}

\subsection{DMD Acceleration}
A way to achieve acceleration is to use results from lower dimensional system projected system to find a correction each iteration until system converges.
The first research of using DMD to accelerate iterative methods was the work of \citet{andersson_novel}.
A Krylov subspace is built up by store the states samples with time sequence as $V_n$, then Gram-Schmidt algorithm is applied by $V_n = E_n U_n$.
The reason why authors would not like to use SVD is that Gram-Schmidt algorithm only work with two state vectors each time and SVD requires the whole subspace matrix $V_n$. 
Moreover, Gram-Schmidt algorithm is obviously a more suitable approach for parallel computations. 
The reduced projection of the system matrix $\tilde{A}$ is obtained by 
\begin{equation}
 \tilde{A} = \mathbf{E}_n^T \mathbf{V}_{n+1} \mathbf{U}_n^{-1}  \, ,
 \label{eq:andersson_reduce}
\end{equation}
and is implemented into iterative linear relation $\mathbf{x}^{(n+1)} = \mathbf{A}\mathbf{x}^{(n)} + \mathbf{b}$.
The estimate of the converged solution can be calculate in the modified form as:
\begin{equation}
 x^{u} = x^{(n+1)} + \mathbf{E}_n(I_n - \tilde{A}_n)^{-1} \mathbf{E}_n^T(x^{(n+2)} - x^{(n+1)}) \, ,
 \label{eq:andersson}
\end{equation}
By performing this process several time to correct the solution, both the number of iterations and the average fluctuation was reduced almost 30\% for compressible flow problems. 

McClarren present a novel acceleration technique for improving the convergence of Richardson(source) iteration for source-driven neutronics problems.\cite{mcclarren_acceleration_2018}
The Richardson iteration can be expressed as 
\begin{equation}
 \mathbf{x}^{(n+1)} = (\mathbf{I}-\mathbf{A})\mathbf{x}^{(n)} + \mathbf{b} \, ,
 \label{eq:richardson}
\end{equation}
where sequence of $\mathbf{x}^{(n)}$ was often saved to build Krylov subspace. 
However, a great feature in his modified DMD acceleration algorithm is that a set successive differences $\mathbf{x}^{(n)}-\mathbf{x}^{(n-1)}$ is used as the columns in the data matrix $\mathbf{Y}_+$ and $\mathbf{Y}_-$ while the standard DMD with SVD decomposition is applied to form the approximation system $\tilde{A}$.
The algorithm is as follows
\begin{enumerate}
 \item Perform R source iterations: $\phi^{l} = \mathbf{A} \phi^{l-1} +b$
 \item Compute K source iterations to form $\mathbf{Y}_+$ and $\mathbf{Y}_-$. The last column of $Y_-$ we call $\phi^{K-1}$ 
 \item Compute $\phi = \phi^{K-1} + \mathbf{U} \Delta y$.
\end{enumerate} 
Here, $U$ is the left unitary matrix from SVD decomposition of $\mathbf{Y}_-$ and $\Delta y$ is computed by 
\begin{equation}
 (\mathbf{I} - \mathbf{\tilde{A}}) \Delta y = \mathbf{U}^T(\phi^{K} - \phi^{K-1})\, ,
 \label{eq:McClarren}
\end{equation}
Results from a homogeneous slab problem and a multi-dimensional pip problem suggest that a sequence of Richardson iterations followed by corrections reduces the number of iterations required by about one order of magnitude.

All of these past successes shows that DMD has potential to estimate the converged dominant modes of a reactor system by extrapolating forward from observed snapshots, even though the sequence of iterations from power method does not means ``real time''.
